# üöÄ Fraud Scoring API ‚Äî Explainable AI (SHAP + LIME)

API em **FastAPI** para detec√ß√£o de fraude em tempo real com foco em **explicabilidade**.  
O projeto simula um fluxo usado por bancos e fintechs: treina um modelo em dados **sint√©ticos** de transa√ß√µes e exp√µe endpoints REST para:

- **Prever** probabilidade de fraude.  
- **Explicar** cada decis√£o usando **SHAP** e **LIME** (explicabilidade exigida por times de **Risco, Compliance e Bacen**).

---

## üß± Tech Stack
- Python 3.11+
- FastAPI + Uvicorn
- scikit-learn (RandomForest + Pipeline)
- SHAP (TreeExplainer)
- LIME (LimeTabularExplainer)
- Docker (deploy pronto)

---

## üì¶ Como rodar localmente
```bash
# 1) Clone e crie ambiente virtual
python -m venv .venv && source .venv/bin/activate   # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt

# 2) (Opcional) Regerar dados e re-treinar o modelo
python -m model.train

# 3) Subir a API
uvicorn app.main:app --reload
# Swagger: http://127.0.0.1:8000/docs


#Docker

docker build -t fraud-explainable-api .
docker run -p 8000:8000 fraud-explainable-api


#Endpoints

POST /predict ‚Üí Probabilidade de fraude + r√≥tulo (0/1).
POST /explain/shap ‚Üí Top features que mais contribu√≠ram (SHAP).
POST /explain/lime ‚Üí Explica√ß√£o local por LIME.

#Exemplo de payload

{
  "amount": 1299.90,
  "channel": "PIX",
  "hour": 1,
  "is_new_device": 1,
  "device_trust_score": 0.23,
  "days_since_last_tx": 0.5,
  "tx_velocity_1h": 7,
  "merchant_risk_score": 0.88,
  "customer_age": 28,
  "has_chargeback_history": 1,
  "country_risk_score": 0.67
}


#Curl r√°pido

curl -X POST http://127.0.0.1:8000/predict \
 -H "Content-Type: application/json" \
 -d '{"amount":1299.9,"channel":"PIX","hour":1,"is_new_device":1,"device_trust_score":0.23,"days_since_last_tx":0.5,"tx_velocity_1h":7,"merchant_risk_score":0.88,"customer_age":28,"has_chargeback_history":1,"country_risk_score":0.67}'


curl -X POST http://127.0.0.1:8000/predict \
 -H "Content-Type: application/json" \
 -d '{"amount":1299.9,"channel":"PIX","hour":1,"is_new_device":1,"device_trust_score":0.23,"days_since_last_tx":0.5,"tx_velocity_1h":7,"merchant_risk_score":0.88,"customer_age":28,"has_chargeback_history":1,"country_risk_score":0.67}'


#Dados sint√©ticos

Os dados s√£o gerados artificialmente (scripts/generate_synthetic_data.py) e reproduzem padr√µes comuns em cen√°rios de fraude:
transa√ß√µes de alto valor
hor√°rios de madrugada
dispositivos novos
estabelecimentos de alto risco
hist√≥rico de chargeback
alta velocidade de transa√ß√µes

#Explicabilidade
SHAP ‚Üí mostra a contribui√ß√£o individual de cada feature para a predi√ß√£o.
LIME ‚Üí gera explica√ß√µes locais aproximando o modelo ao redor de cada inst√¢ncia.
‚ö†Ô∏è Este projeto √© educacional. Explicabilidade n√£o substitui governan√ßa de modelos, fairness ou monitoramento em produ√ß√£o (drift, estabilidade, etc.).


‚úÖ #Testes automatizados

pytest -q
# sa√≠da esperada: 2 passed in Xs


#Por que importa para o setor financeiro?
Transpar√™ncia: decis√µes de fraude audit√°veis para Bacen e auditorias.
Suporte a analistas de fraude: entender por que uma transa√ß√£o foi marcada como suspeita.
Compliance & Riscos: comunica√ß√£o clara com √°reas regulat√≥rias.

‚ú® Projeto criado para demonstrar boas pr√°ticas de ML + MLOps + Explainable AI.
Made with ‚ù§Ô∏è por Bianca Sena

---

üëâ Esse README j√° equilibra: parte t√©cnica (pra devs) + impacto de neg√≥cio

Quer que eu prepare tamb√©m uma **se√ß√£o visual com badges (shields.io)** no topo? Assim voc√™ teria √≠cones tipo ‚ÄúPython‚Äù, ‚ÄúFastAPI‚Äù, ‚ÄúDocker‚Äù, ‚ÄúSHAP‚Äù logo abaixo do t√≠tulo. Isso chama muito a aten√ß√£o quando algu√©m abre o GitHub.
